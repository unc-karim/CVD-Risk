{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "download_dataset",
        "outputId": "372e30ca-1344-4e8e-f5c9-db0de9aac121"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from Figshare article 27907056...\n",
            "Downloading data_info.json...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "data_info.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 736k/736k [00:00<00:00, 1.06MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Fundus_CIMT_2903.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fundus_CIMT_2903.zip: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.50G/1.50G [01:21<00:00, 19.8MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting Fundus_CIMT_2903.zip...\n",
            "\n",
            "âœ… Dataset download complete!\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Download dataset from Figshare\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "DATA_ROOT = Path(\"/content/data/China_Fundus_CIMT\")\n",
        "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def download_figshare_dataset(article_id=27907056, out_dir=DATA_ROOT):\n",
        "    \"\"\"Download China-Fundus-CIMT dataset from Figshare\"\"\"\n",
        "    print(f\"Downloading from Figshare article {article_id}...\")\n",
        "    api_url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
        "\n",
        "    r = requests.get(api_url)\n",
        "    r.raise_for_status()\n",
        "    meta = r.json()\n",
        "\n",
        "    files = meta.get(\"files\", [])\n",
        "    if not files:\n",
        "        raise ValueError(\"No files found in Figshare article\")\n",
        "\n",
        "    for file_info in files:\n",
        "        name = file_info['name']\n",
        "        url = file_info['download_url']\n",
        "        dest = out_dir / name\n",
        "\n",
        "        if dest.exists():\n",
        "            print(f\"âœ“ {name} already exists, skipping\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Downloading {name}...\")\n",
        "        response = requests.get(url, stream=True)\n",
        "        total_size = int(response.headers.get('content-length', 0))\n",
        "\n",
        "        with open(dest, 'wb') as f, tqdm(\n",
        "            desc=name,\n",
        "            total=total_size,\n",
        "            unit='iB',\n",
        "            unit_scale=True,\n",
        "            unit_divisor=1024,\n",
        "        ) as pbar:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                size = f.write(chunk)\n",
        "                pbar.update(size)\n",
        "\n",
        "        if dest.suffix == '.zip':\n",
        "            print(f\"Extracting {name}...\")\n",
        "            with zipfile.ZipFile(dest, 'r') as zip_ref:\n",
        "                zip_ref.extractall(out_dir)\n",
        "            dest.unlink()\n",
        "\n",
        "    print(\"\\nâœ… Dataset download complete!\")\n",
        "\n",
        "if not (DATA_ROOT / \"Fundus_CIMT_2903 Dataset\").exists():\n",
        "    download_figshare_dataset()\n",
        "else:\n",
        "    print(\"âœ… Dataset already exists\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "verify_dataset",
        "outputId": "ea84e091-d1ff-4d7c-9317-992b4e53a7c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            "âœ… China_Fundus_CIMT imagesâ‰ˆ5,806    path=/content/data/China_Fundus_CIMT\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Verify dataset\n",
        "DATA_ROOT = Path(\"/content/data\")\n",
        "DATASETS = {\n",
        "    \"China_Fundus_CIMT\": DATA_ROOT / \"China_Fundus_CIMT\",\n",
        "}\n",
        "\n",
        "img_exts = {\".png\",\".jpg\",\".jpeg\",\".tif\",\".tiff\",\".bmp\",\".gif\"}\n",
        "\n",
        "def count_by_ext(d: Path, exts):\n",
        "    return sum(1 for p in d.rglob(\"*\") if p.is_file() and p.suffix.lower() in exts)\n",
        "\n",
        "print(\"Summary:\")\n",
        "for name, root in DATASETS.items():\n",
        "    if not root.exists():\n",
        "        continue\n",
        "    n_img = count_by_ext(root, img_exts)\n",
        "    print(f\"âœ… {name:<16} imagesâ‰ˆ{n_img:,}    path={root}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "preprocess_dataset",
        "outputId": "6905fd8e-5f17-4e7c-d03e-db4ef3f33d42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading metadata...\n",
            "âœ… Metadata saved: 2903 patients\n",
            "   Train: 2603\n",
            "   Val: 200\n",
            "   Test: 100\n",
            "\n",
            "Copying images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2903/2903 [00:05<00:00, 490.48it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Preprocessing complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Preprocess the dataset\n",
        "import json\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "# Configuration\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "RAW_DATA_ROOT = Path(\"/content/data/China_Fundus_CIMT\")\n",
        "DATASET_FOLDER = RAW_DATA_ROOT / \"Fundus_CIMT_2903 Dataset\"\n",
        "DATA_INFO_JSON = RAW_DATA_ROOT / \"data_info.json\"\n",
        "\n",
        "PROCESSED_ROOT = Path(\"/content/processed_data/CIMT\")\n",
        "PROCESSED_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "TARGET_SIZE = (512, 512)\n",
        "\n",
        "print(\"Loading metadata...\")\n",
        "with open(DATA_INFO_JSON, 'r') as f:\n",
        "    metadata_dict = json.load(f)\n",
        "\n",
        "# Create metadata CSV\n",
        "metadata_list = []\n",
        "for patient_id, info in metadata_dict.items():\n",
        "    metadata_list.append({\n",
        "        'patient_id': patient_id,\n",
        "        'age': info['True_age'],\n",
        "        'age_norm': info['age'],  # Normalized age\n",
        "        'gender': info['gender'],  # 0=female, 1=male\n",
        "        'thickness': info['thickness'],  # CIMT values (will parse this)\n",
        "        'label': info['label'],  # 0=normal, 1=thickened (for reference)\n",
        "        'group': info['group'],  # 1=train, 2=val, 3=test\n",
        "        'left_image': info['left_eye'],\n",
        "        'right_image': info['right_eye']\n",
        "    })\n",
        "\n",
        "metadata_df = pd.DataFrame(metadata_list)\n",
        "metadata_df.to_csv(PROCESSED_ROOT / \"metadata.csv\", index=False)\n",
        "\n",
        "print(f\"âœ… Metadata saved: {len(metadata_df)} patients\")\n",
        "print(f\"   Train: {(metadata_df['group']==1).sum()}\")\n",
        "print(f\"   Val: {(metadata_df['group']==2).sum()}\")\n",
        "print(f\"   Test: {(metadata_df['group']==3).sum()}\")\n",
        "\n",
        "# Copy images to processed folder\n",
        "images_out = PROCESSED_ROOT / \"images\"\n",
        "images_out.mkdir(exist_ok=True)\n",
        "\n",
        "print(\"\\nCopying images...\")\n",
        "for _, row in tqdm(metadata_df.iterrows(), total=len(metadata_df), desc=\"Processing\"):\n",
        "    for eye in ['left_image', 'right_image']:\n",
        "        src = DATASET_FOLDER / row[eye]\n",
        "        dst = images_out / row[eye]\n",
        "        if src.exists() and not dst.exists():\n",
        "            shutil.copy(src, dst)\n",
        "\n",
        "print(\"\\nâœ… Preprocessing complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "configuration",
        "outputId": "bb7d3b4b-46c8-4eb2-b225-9d1552f92388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "CONFIGURATION LOADED - CIMT REGRESSION\n",
            "============================================================\n",
            "Device: cuda\n",
            "GPU: NVIDIA L4\n",
            "GPU Memory: 23.80 GB\n",
            "\n",
            "ðŸ’¾ Memory Optimizations:\n",
            "   â€¢ Batch size: 24\n",
            "   â€¢ Gradient accumulation: 8\n",
            "   â€¢ Effective batch: 192\n",
            "   â€¢ Mixed precision: True\n",
            "\n",
            "ðŸŽ¯ Training Configuration:\n",
            "   â€¢ Stage 1: 30 epochs\n",
            "   â€¢ Stage 2: 20 epochs\n",
            "   â€¢ Loss: smooth_l1\n",
            "   â€¢ Metric: mae (lower is better)\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Configuration - OPTIMIZED FOR COLAB FREE\n",
        "import torch\n",
        "\n",
        "# ==================== PATHS ====================\n",
        "PROCESSED_ROOT = Path(\"/content/processed_data/CIMT\")\n",
        "METADATA_CSV = PROCESSED_ROOT / \"metadata.csv\"\n",
        "IMAGES_DIR = PROCESSED_ROOT / \"images\"\n",
        "\n",
        "OUTPUT_DIR = Path(\"/content/outputs/cimt_regression\")\n",
        "CHECKPOINT_DIR = OUTPUT_DIR / \"checkpoints\"\n",
        "LOGS_DIR = OUTPUT_DIR / \"logs\"\n",
        "RESULTS_DIR = OUTPUT_DIR / \"results\"\n",
        "\n",
        "for dir_path in [OUTPUT_DIR, CHECKPOINT_DIR, LOGS_DIR, RESULTS_DIR]:\n",
        "    dir_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ==================== MODEL ====================\n",
        "MODEL_NAME = \"seresnext50_32x4d\"\n",
        "USE_PRETRAINED = True\n",
        "USE_MULTIMODAL = True\n",
        "\n",
        "CLINICAL_INPUT_DIM = 3  # age + gender (2)\n",
        "CLINICAL_HIDDEN_DIM = 128\n",
        "BACKBONE_OUTPUT_DIM = 2048\n",
        "FUSION_HIDDEN_DIMS = [512, 128]\n",
        "DROPOUT_RATE = 0.5\n",
        "\n",
        "# ==================== DATA - OPTIMIZED ====================\n",
        "IMAGE_SIZE = 512\n",
        "BATCH_SIZE = 24  # âš ï¸ Small for Colab free (15GB RAM)\n",
        "NUM_WORKERS = 2\n",
        "PIN_MEMORY = True\n",
        "GRADIENT_ACCUMULATION_STEPS = 8  # Effective batch = 2Ã—8 = 16\n",
        "\n",
        "# ==================== TRAINING - REDUCED ====================\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "SEED = 42\n",
        "USE_MIXED_PRECISION = True  # Essential for Colab free\n",
        "\n",
        "# Reduced epochs for faster training\n",
        "STAGE1_EPOCHS = 30  # Reduced from 100\n",
        "STAGE1_LR = 0.001\n",
        "STAGE1_LR_DECAY_FACTOR = 0.1\n",
        "STAGE1_LR_DECAY_EVERY = 15\n",
        "\n",
        "STAGE2_EPOCHS = 20  # Reduced from 100\n",
        "STAGE2_LR = 0.00001\n",
        "STAGE2_LR_DECAY_FACTOR = 0.1\n",
        "STAGE2_LR_DECAY_EVERY = 10\n",
        "\n",
        "OPTIMIZER = \"adam\"\n",
        "WEIGHT_DECAY = 1e-4\n",
        "BETAS = (0.9, 0.999)\n",
        "LOSS_TYPE = \"smooth_l1\"  # Changed from 'weighted_bce'\n",
        "\n",
        "# ==================== AUGMENTATION ====================\n",
        "HORIZONTAL_FLIP_PROB = 0.5\n",
        "VERTICAL_FLIP_PROB = 0.5\n",
        "ROTATION_RANGE = 20\n",
        "COLOR_JITTER = True\n",
        "BRIGHTNESS = 0.2\n",
        "CONTRAST = 0.2\n",
        "SATURATION = 0.2\n",
        "HUE = 0.1\n",
        "\n",
        "NORMALIZE_MEAN = [0.485, 0.456, 0.406]\n",
        "NORMALIZE_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "# ==================== EVALUATION ====================\n",
        "SAVE_BEST_MODEL = True\n",
        "METRIC_FOR_BEST = \"mae\"  # Changed from 'auc' - lower is better\n",
        "EARLY_STOPPING_PATIENCE = 15\n",
        "LOG_INTERVAL = 10\n",
        "SAVE_INTERVAL = 5\n",
        "\n",
        "# ==================== REGRESSION SPECIFIC ====================\n",
        "CIMT_THRESHOLD = 0.9  # mm - for optional binary classification metrics\n",
        "\n",
        "# ==================== SUMMARY ====================\n",
        "print(\"=\"*60)\n",
        "print(\"CONFIGURATION LOADED - CIMT REGRESSION\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Device: {DEVICE}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "print(f\"\\nðŸ’¾ Memory Optimizations:\")\n",
        "print(f\"   â€¢ Batch size: {BATCH_SIZE}\")\n",
        "print(f\"   â€¢ Gradient accumulation: {GRADIENT_ACCUMULATION_STEPS}\")\n",
        "print(f\"   â€¢ Effective batch: {BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS}\")\n",
        "print(f\"   â€¢ Mixed precision: {USE_MIXED_PRECISION}\")\n",
        "print(f\"\\nðŸŽ¯ Training Configuration:\")\n",
        "print(f\"   â€¢ Stage 1: {STAGE1_EPOCHS} epochs\")\n",
        "print(f\"   â€¢ Stage 2: {STAGE2_EPOCHS} epochs\")\n",
        "print(f\"   â€¢ Loss: {LOSS_TYPE}\")\n",
        "print(f\"   â€¢ Metric: {METRIC_FOR_BEST} (lower is better)\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utility_functions",
        "outputId": "b0f2ffc6-8156-4f8a-f855-4ae054484bd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Utility functions defined\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Utility functions\n",
        "def set_seed(seed):\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(SEED)\n",
        "\n",
        "def parse_cimt_value(thickness_str):\n",
        "    \"\"\"\n",
        "    Parse CIMT thickness string to extract continuous value in mm.\n",
        "    Returns max(left, right) as the target CIMT value.\n",
        "\n",
        "    Example formats:\n",
        "    - \"0.85, 0.90\" -> extract left=0.85, right=0.90, return 0.90\n",
        "    - \"0.95\" -> return 0.95\n",
        "    \"\"\"\n",
        "    if pd.isna(thickness_str) or thickness_str == '':\n",
        "        return None\n",
        "\n",
        "    thickness_str = str(thickness_str).strip()\n",
        "\n",
        "    # Try to parse comma-separated values\n",
        "    if ',' in thickness_str:\n",
        "        parts = [p.strip() for p in thickness_str.split(',')]\n",
        "        values = []\n",
        "        for p in parts:\n",
        "            try:\n",
        "                values.append(float(p))\n",
        "            except ValueError:\n",
        "                continue\n",
        "        if values:\n",
        "            return max(values)  # Return max of left and right\n",
        "\n",
        "    # Try single value\n",
        "    try:\n",
        "        return float(thickness_str)\n",
        "    except ValueError:\n",
        "        return None\n",
        "\n",
        "print(\"âœ… Utility functions defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "transforms",
        "outputId": "da638f7c-1650-4154-fe96-ac9d86cfc4a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Transforms defined\n"
          ]
        }
      ],
      "source": [
        "# Cell 6: Data transforms\n",
        "from torchvision import transforms\n",
        "\n",
        "def get_transforms():\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "        transforms.RandomHorizontalFlip(p=HORIZONTAL_FLIP_PROB),\n",
        "        transforms.RandomVerticalFlip(p=VERTICAL_FLIP_PROB),\n",
        "        transforms.RandomRotation(degrees=ROTATION_RANGE),\n",
        "        transforms.ColorJitter(\n",
        "            brightness=BRIGHTNESS,\n",
        "            contrast=CONTRAST,\n",
        "            saturation=SATURATION,\n",
        "            hue=HUE\n",
        "        ) if COLOR_JITTER else transforms.Lambda(lambda x: x),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=NORMALIZE_MEAN, std=NORMALIZE_STD)\n",
        "    ])\n",
        "\n",
        "    val_transform = transforms.Compose([\n",
        "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=NORMALIZE_MEAN, std=NORMALIZE_STD)\n",
        "    ])\n",
        "\n",
        "    return train_transform, val_transform\n",
        "\n",
        "print(\"âœ… Transforms defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dataset",
        "outputId": "bbc2af76-4cf4-42e1-cab0-6a62fd3342a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Dataset class defined\n"
          ]
        }
      ],
      "source": [
        "# Cell 7: Dataset class - MODIFIED FOR REGRESSION\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CIMTRegressionDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset for CIMT regression task.\n",
        "    Returns continuous CIMT value in mm (not binary label).\n",
        "    \"\"\"\n",
        "    def __init__(self, metadata_csv, images_dir, split=\"train\",\n",
        "                 transform=None, use_multimodal=True):\n",
        "        self.images_dir = Path(images_dir)\n",
        "        self.transform = transform\n",
        "        self.use_multimodal = use_multimodal\n",
        "        self.split = split\n",
        "\n",
        "        # Load metadata\n",
        "        df = pd.read_csv(metadata_csv)\n",
        "\n",
        "        # Filter by split (group: 1=train, 2=val, 3=test)\n",
        "        split_map = {'train': 1, 'val': 2, 'test': 3}\n",
        "        df = df[df['group'] == split_map[split]].copy()\n",
        "\n",
        "        # Parse CIMT values from thickness column\n",
        "        df['cimt_mm'] = df['thickness'].apply(parse_cimt_value)\n",
        "\n",
        "        # Remove samples with missing CIMT values\n",
        "        df = df.dropna(subset=['cimt_mm']).reset_index(drop=True)\n",
        "\n",
        "        self.data = df\n",
        "\n",
        "        # Statistics\n",
        "        cimt_values = self.data['cimt_mm'].values\n",
        "        print(f\"{split.upper()}: {len(self.data)} patients\")\n",
        "        print(f\"  CIMT range: [{cimt_values.min():.2f}, {cimt_values.max():.2f}] mm\")\n",
        "        print(f\"  CIMT meanÂ±std: {cimt_values.mean():.2f}Â±{cimt_values.std():.2f} mm\")\n",
        "        print(f\"  Thickened (â‰¥{CIMT_THRESHOLD}mm): {(cimt_values >= CIMT_THRESHOLD).sum()}\")\n",
        "        print(f\"  Normal (<{CIMT_THRESHOLD}mm): {(cimt_values < CIMT_THRESHOLD).sum()}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "\n",
        "        # Load images\n",
        "        left_path = self.images_dir / row['left_image']\n",
        "        right_path = self.images_dir / row['right_image']\n",
        "\n",
        "        left_img = Image.open(left_path).convert('RGB')\n",
        "        right_img = Image.open(right_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            left_img = self.transform(left_img)\n",
        "            right_img = self.transform(right_img)\n",
        "\n",
        "        # Clinical features\n",
        "        age = torch.tensor([row['age_norm']], dtype=torch.float32)\n",
        "        gender = torch.tensor([1-row['gender'], row['gender']], dtype=torch.float32)\n",
        "        clinical = torch.cat([age, gender])\n",
        "\n",
        "        # CIMT value (continuous target) - shape [1]\n",
        "        cimt_value = torch.tensor([row['cimt_mm']], dtype=torch.float32)\n",
        "\n",
        "        return {\n",
        "            'left_image': left_img,\n",
        "            'right_image': right_img,\n",
        "            'clinical': clinical,\n",
        "            'cimt': cimt_value,  # Changed from 'label' to 'cimt'\n",
        "            'patient_id': row['patient_id']\n",
        "        }\n",
        "\n",
        "\n",
        "def get_dataloaders():\n",
        "    train_transform, val_transform = get_transforms()\n",
        "\n",
        "    train_dataset = CIMTRegressionDataset(METADATA_CSV, IMAGES_DIR, 'train',\n",
        "                                          train_transform, USE_MULTIMODAL)\n",
        "    val_dataset = CIMTRegressionDataset(METADATA_CSV, IMAGES_DIR, 'val',\n",
        "                                        val_transform, USE_MULTIMODAL)\n",
        "    test_dataset = CIMTRegressionDataset(METADATA_CSV, IMAGES_DIR, 'test',\n",
        "                                         val_transform, USE_MULTIMODAL)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
        "                             shuffle=True, num_workers=NUM_WORKERS,\n",
        "                             pin_memory=PIN_MEMORY, drop_last=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
        "                           shuffle=False, num_workers=NUM_WORKERS,\n",
        "                           pin_memory=PIN_MEMORY)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
        "                            shuffle=False, num_workers=NUM_WORKERS,\n",
        "                            pin_memory=PIN_MEMORY)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "print(\"âœ… Dataset class defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "model",
        "outputId": "763386de-25d4-4948-9e3b-93156edd5a87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model architecture defined\n"
          ]
        }
      ],
      "source": [
        "# Cell 8: Model architecture - MODIFIED FOR REGRESSION\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "\n",
        "class SiameseMultimodalCIMTRegression(nn.Module):\n",
        "    \"\"\"\n",
        "    Siamese multimodal model for CIMT regression.\n",
        "    Outputs a single scalar value (CIMT in mm) with no activation.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Shared backbone for both eyes (unchanged)\n",
        "        self.backbone = timm.create_model(\n",
        "            MODEL_NAME,\n",
        "            pretrained=USE_PRETRAINED,\n",
        "            num_classes=0,  # Remove classification head\n",
        "            global_pool='avg'\n",
        "        )\n",
        "\n",
        "        # Clinical feature processor (unchanged)\n",
        "        self.clinical_fc = nn.Sequential(\n",
        "            nn.Linear(CLINICAL_INPUT_DIM, CLINICAL_HIDDEN_DIM),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(DROPOUT_RATE)\n",
        "        )\n",
        "\n",
        "        # Fusion layers - modified for regression\n",
        "        fusion_input_dim = BACKBONE_OUTPUT_DIM * 2 + CLINICAL_HIDDEN_DIM\n",
        "\n",
        "        layers = []\n",
        "        in_dim = fusion_input_dim\n",
        "        for hidden_dim in FUSION_HIDDEN_DIMS:\n",
        "            layers.extend([\n",
        "                nn.Linear(in_dim, hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(DROPOUT_RATE)\n",
        "            ])\n",
        "            in_dim = hidden_dim\n",
        "\n",
        "        # Final regression head: outputs 1 scalar, no activation\n",
        "        layers.append(nn.Linear(in_dim, 1))  # Changed: no sigmoid\n",
        "        self.fusion = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, left_img, right_img, clinical):\n",
        "        # Extract features from both eyes (shared weights)\n",
        "        left_features = self.backbone(left_img)\n",
        "        right_features = self.backbone(right_img)\n",
        "\n",
        "        # Concatenate bilateral features\n",
        "        bilateral_features = torch.cat([left_features, right_features], dim=1)\n",
        "\n",
        "        # Process clinical features\n",
        "        clinical_features = self.clinical_fc(clinical)\n",
        "\n",
        "        # Fuse all features\n",
        "        fused = torch.cat([bilateral_features, clinical_features], dim=1)\n",
        "\n",
        "        # Regression output (no sigmoid, pure linear output)\n",
        "        output = self.fusion(fused)  # Shape: [batch_size, 1]\n",
        "\n",
        "        return output\n",
        "\n",
        "print(\"âœ… Model architecture defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "metrics",
        "outputId": "65bb7af1-d2c9-48c9-b3dd-c2554e821014"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Metrics defined\n"
          ]
        }
      ],
      "source": [
        "# Cell 9: Loss and metrics - MODIFIED FOR REGRESSION\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "class RegressionMetricsCalculator:\n",
        "    \"\"\"\n",
        "    Calculate regression metrics: MAE, RMSE, RÂ²\n",
        "    Optionally calculate binary classification metrics at threshold.\n",
        "    \"\"\"\n",
        "    def __init__(self, threshold=CIMT_THRESHOLD):\n",
        "        self.threshold = threshold\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.predictions = []\n",
        "        self.targets = []\n",
        "\n",
        "    def update(self, predictions, targets):\n",
        "        \"\"\"\n",
        "        predictions: tensor of shape [batch_size, 1]\n",
        "        targets: tensor of shape [batch_size, 1]\n",
        "        \"\"\"\n",
        "        self.predictions.extend(predictions.cpu().numpy().flatten())\n",
        "        self.targets.extend(targets.cpu().numpy().flatten())\n",
        "\n",
        "    def compute(self):\n",
        "        y_true = np.array(self.targets)\n",
        "        y_pred = np.array(self.predictions)\n",
        "\n",
        "        # Regression metrics\n",
        "        mae = mean_absolute_error(y_true, y_pred)\n",
        "        mse = mean_squared_error(y_true, y_pred)\n",
        "        rmse = np.sqrt(mse)\n",
        "\n",
        "        # RÂ² (coefficient of determination)\n",
        "        r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "        metrics = {\n",
        "            'mae': mae,\n",
        "            'rmse': rmse,\n",
        "            'mse': mse,\n",
        "            'r2': r2\n",
        "        }\n",
        "\n",
        "        # Optional: Binary classification metrics at threshold\n",
        "        y_true_binary = (y_true >= self.threshold).astype(int)\n",
        "        y_pred_binary = (y_pred >= self.threshold).astype(int)\n",
        "\n",
        "        accuracy = (y_true_binary == y_pred_binary).mean()\n",
        "\n",
        "        metrics['threshold_accuracy'] = accuracy\n",
        "        metrics['threshold'] = self.threshold\n",
        "\n",
        "        return metrics\n",
        "\n",
        "print(\"âœ… Metrics defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "training_functions",
        "outputId": "e5bc438d-881f-42d6-bc58-726e6d5205d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Training functions defined\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "from torch.amp import autocast, GradScaler # Changed import from torch.cuda.amp\n",
        "import time\n",
        "\n",
        "# Enable mixed precision\n",
        "scaler = GradScaler() if USE_MIXED_PRECISION else None\n",
        "\n",
        "def train_epoch(model, dataloader, criterion, optimizer, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    metrics_calc = RegressionMetricsCalculator()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    pbar = tqdm(dataloader, desc=f'Epoch {epoch} [Train]')\n",
        "    for batch_idx, batch in enumerate(pbar):\n",
        "        left_img = batch['left_image'].to(DEVICE)\n",
        "        right_img = batch['right_image'].to(DEVICE)\n",
        "        clinical = batch['clinical'].to(DEVICE)\n",
        "        targets = batch['cimt'].to(DEVICE)  # Changed from 'label' to 'cimt'\n",
        "\n",
        "        # Forward pass with mixed precision\n",
        "        if USE_MIXED_PRECISION:\n",
        "            with autocast(device_type=DEVICE.type): # Changed from 'cuda' to DEVICE.type\n",
        "                predictions = model(left_img, right_img, clinical)  # No sigmoid\n",
        "                loss = criterion(predictions, targets)\n",
        "                loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # Update every N steps\n",
        "            if (batch_idx + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad()\n",
        "        else:\n",
        "            predictions = model(left_img, right_img, clinical)\n",
        "            loss = criterion(predictions, targets)\n",
        "            loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
        "            loss.backward()\n",
        "\n",
        "            if (batch_idx + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "        running_loss += loss.item() * GRADIENT_ACCUMULATION_STEPS\n",
        "\n",
        "        # Update metrics (no sigmoid needed for predictions)\n",
        "        metrics_calc.update(predictions.detach(), targets)\n",
        "\n",
        "        pbar.set_postfix({'loss': running_loss / (batch_idx + 1)})\n",
        "\n",
        "    metrics = metrics_calc.compute()\n",
        "    metrics['loss'] = running_loss / len(dataloader)\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def validate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    metrics_calc = RegressionMetricsCalculator()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc='Validating'):\n",
        "            left_img = batch['left_image'].to(DEVICE)\n",
        "            right_img = batch['right_image'].to(DEVICE)\n",
        "            clinical = batch['clinical'].to(DEVICE)\n",
        "            targets = batch['cimt'].to(DEVICE)  # Changed from 'label' to 'cimt'\n",
        "\n",
        "            if USE_MIXED_PRECISION:\n",
        "                with autocast(device_type=DEVICE.type): # Changed from 'cuda' to DEVICE.type\n",
        "                    predictions = model(left_img, right_img, clinical)  # No sigmoid\n",
        "                    loss = criterion(predictions, targets)\n",
        "            else:\n",
        "                predictions = model(left_img, right_img, clinical)\n",
        "                loss = criterion(predictions, targets)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Update metrics (no sigmoid needed)\n",
        "            metrics_calc.update(predictions, targets)\n",
        "\n",
        "    metrics = metrics_calc.compute()\n",
        "    metrics['loss'] = running_loss / len(dataloader)\n",
        "    return metrics\n",
        "\n",
        "print(\"âœ… Training functions defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573,
          "referenced_widgets": [
            "ec2036c7c6bf4296a1d53486fb53d7e9",
            "8d44539a7d1f4bbf99c8180dcf89b27f",
            "33b0432244b5448b80b9185df53fbe36",
            "540051b772f54fcbb090fe43db119f29",
            "4681fd8a45524777b2c0b8e7a0879dd4",
            "ac2fc7729021457aa9453ed093b43cd1",
            "7a51a3efc0894cfebb1f91e7bc8baccb",
            "3a3b57d33e8044c28925e6d633f06058",
            "a9ffb805a967463486f7159ca88bdd33",
            "bda35c0235cc48e28b39055a1e00d8d9",
            "639c138a1ecd4cdb8f2c1208b54dee91"
          ]
        },
        "id": "initialize",
        "outputId": "c3b0c135-9c61-4930-f44f-6868f7efe031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing...\n",
            "TRAIN: 2603 patients\n",
            "  CIMT range: [0.50, 1.70] mm\n",
            "  CIMT meanÂ±std: 1.00Â±0.18 mm\n",
            "  Thickened (â‰¥0.9mm): 1904\n",
            "  Normal (<0.9mm): 699\n",
            "VAL: 200 patients\n",
            "  CIMT range: [0.50, 1.40] mm\n",
            "  CIMT meanÂ±std: 0.92Â±0.21 mm\n",
            "  Thickened (â‰¥0.9mm): 100\n",
            "  Normal (<0.9mm): 100\n",
            "TEST: 100 patients\n",
            "  CIMT range: [0.50, 1.50] mm\n",
            "  CIMT meanÂ±std: 0.91Â±0.19 mm\n",
            "  Thickened (â‰¥0.9mm): 50\n",
            "  Normal (<0.9mm): 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/111M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec2036c7c6bf4296a1d53486fb53d7e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Model created with 27,740,401 parameters\n",
            "Loss function: SmoothL1Loss\n",
            "\n",
            "============================================================\n",
            "READY TO TRAIN!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Cell 11: Initialize everything\n",
        "print(\"Initializing...\")\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader, val_loader, test_loader = get_dataloaders()\n",
        "\n",
        "# Create model\n",
        "model = SiameseMultimodalCIMTRegression().to(DEVICE)\n",
        "print(f\"\\nâœ… Model created with {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
        "\n",
        "# Loss function - changed from BCE to MSE/SmoothL1\n",
        "if LOSS_TYPE == \"mse\":\n",
        "    criterion = nn.MSELoss()\n",
        "elif LOSS_TYPE == \"smooth_l1\":\n",
        "    criterion = nn.SmoothL1Loss()  # More robust to outliers\n",
        "else:\n",
        "    raise ValueError(f\"Unknown loss type: {LOSS_TYPE}\")\n",
        "\n",
        "print(f\"Loss function: {criterion.__class__.__name__}\")\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=STAGE1_LR,\n",
        "                      weight_decay=WEIGHT_DECAY, betas=BETAS)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"READY TO TRAIN!\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "training_stage1",
        "outputId": "fba5f86f-5d49-40e7-f617-dbcba95efa3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STAGE 1: Training with higher LR\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:49<00:00,  1.02s/it, loss=0.146]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30:\n",
            "  Train - Loss: 0.1464, MAE: 0.413mm, RMSE: 0.560mm, RÂ²: -8.335\n",
            "  Val   - Loss: 0.0201, MAE: 0.170mm, RMSE: 0.201mm, RÂ²: 0.115\n",
            "  Val Threshold Acc (@0.9mm): 0.630\n",
            "  LR: 0.001000\n",
            "  âœ… New best MAE: 0.1703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:42<00:00,  1.05it/s, loss=0.0407]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2/30:\n",
            "  Train - Loss: 0.0407, MAE: 0.228mm, RMSE: 0.285mm, RÂ²: -1.414\n",
            "  Val   - Loss: 0.0220, MAE: 0.173mm, RMSE: 0.204mm, RÂ²: 0.084\n",
            "  Val Threshold Acc (@0.9mm): 0.600\n",
            "  LR: 0.001000\n",
            "  Patience: 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:44<00:00,  1.03it/s, loss=0.0354]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3/30:\n",
            "  Train - Loss: 0.0354, MAE: 0.210mm, RMSE: 0.266mm, RÂ²: -1.100\n",
            "  Val   - Loss: 0.0203, MAE: 0.163mm, RMSE: 0.208mm, RÂ²: 0.050\n",
            "  Val Threshold Acc (@0.9mm): 0.620\n",
            "  LR: 0.001000\n",
            "  âœ… New best MAE: 0.1629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:45<00:00,  1.02it/s, loss=0.0327]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4/30:\n",
            "  Train - Loss: 0.0327, MAE: 0.203mm, RMSE: 0.256mm, RÂ²: -0.945\n",
            "  Val   - Loss: 0.0221, MAE: 0.169mm, RMSE: 0.218mm, RÂ²: -0.042\n",
            "  Val Threshold Acc (@0.9mm): 0.565\n",
            "  LR: 0.001000\n",
            "  Patience: 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:42<00:00,  1.05it/s, loss=0.0313]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5/30:\n",
            "  Train - Loss: 0.0313, MAE: 0.199mm, RMSE: 0.250mm, RÂ²: -0.855\n",
            "  Val   - Loss: 0.0152, MAE: 0.147mm, RMSE: 0.176mm, RÂ²: 0.320\n",
            "  Val Threshold Acc (@0.9mm): 0.735\n",
            "  LR: 0.001000\n",
            "  âœ… New best MAE: 0.1469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:42<00:00,  1.05it/s, loss=0.0294]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6/30:\n",
            "  Train - Loss: 0.0294, MAE: 0.194mm, RMSE: 0.242mm, RÂ²: -0.746\n",
            "  Val   - Loss: 0.0155, MAE: 0.148mm, RMSE: 0.178mm, RÂ²: 0.302\n",
            "  Val Threshold Acc (@0.9mm): 0.780\n",
            "  LR: 0.001000\n",
            "  Patience: 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:43<00:00,  1.04it/s, loss=0.0258]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7/30:\n",
            "  Train - Loss: 0.0258, MAE: 0.182mm, RMSE: 0.227mm, RÂ²: -0.527\n",
            "  Val   - Loss: 0.0164, MAE: 0.147mm, RMSE: 0.180mm, RÂ²: 0.288\n",
            "  Val Threshold Acc (@0.9mm): 0.690\n",
            "  LR: 0.001000\n",
            "  Patience: 2/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:46<00:00,  1.02it/s, loss=0.026]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8/30:\n",
            "  Train - Loss: 0.0260, MAE: 0.182mm, RMSE: 0.228mm, RÂ²: -0.542\n",
            "  Val   - Loss: 0.0144, MAE: 0.141mm, RMSE: 0.172mm, RÂ²: 0.351\n",
            "  Val Threshold Acc (@0.9mm): 0.775\n",
            "  LR: 0.001000\n",
            "  âœ… New best MAE: 0.1410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:44<00:00,  1.03it/s, loss=0.0261]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9/30:\n",
            "  Train - Loss: 0.0261, MAE: 0.181mm, RMSE: 0.229mm, RÂ²: -0.559\n",
            "  Val   - Loss: 0.0145, MAE: 0.143mm, RMSE: 0.172mm, RÂ²: 0.352\n",
            "  Val Threshold Acc (@0.9mm): 0.740\n",
            "  LR: 0.001000\n",
            "  Patience: 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:43<00:00,  1.04it/s, loss=0.025]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10/30:\n",
            "  Train - Loss: 0.0250, MAE: 0.177mm, RMSE: 0.224mm, RÂ²: -0.485\n",
            "  Val   - Loss: 0.0147, MAE: 0.141mm, RMSE: 0.172mm, RÂ²: 0.351\n",
            "  Val Threshold Acc (@0.9mm): 0.740\n",
            "  LR: 0.001000\n",
            "  âœ… New best MAE: 0.1407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:42<00:00,  1.05it/s, loss=0.0249]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 11/30:\n",
            "  Train - Loss: 0.0249, MAE: 0.179mm, RMSE: 0.223mm, RÂ²: -0.481\n",
            "  Val   - Loss: 0.0159, MAE: 0.146mm, RMSE: 0.177mm, RÂ²: 0.309\n",
            "  Val Threshold Acc (@0.9mm): 0.685\n",
            "  LR: 0.001000\n",
            "  Patience: 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:44<00:00,  1.03it/s, loss=0.0236]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 12/30:\n",
            "  Train - Loss: 0.0236, MAE: 0.173mm, RMSE: 0.217mm, RÂ²: -0.409\n",
            "  Val   - Loss: 0.0143, MAE: 0.141mm, RMSE: 0.170mm, RÂ²: 0.366\n",
            "  Val Threshold Acc (@0.9mm): 0.760\n",
            "  LR: 0.001000\n",
            "  Patience: 2/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:46<00:00,  1.01it/s, loss=0.0244]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 13/30:\n",
            "  Train - Loss: 0.0244, MAE: 0.176mm, RMSE: 0.221mm, RÂ²: -0.451\n",
            "  Val   - Loss: 0.0137, MAE: 0.137mm, RMSE: 0.169mm, RÂ²: 0.376\n",
            "  Val Threshold Acc (@0.9mm): 0.785\n",
            "  LR: 0.001000\n",
            "  âœ… New best MAE: 0.1374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:43<00:00,  1.04it/s, loss=0.0247]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 14/30:\n",
            "  Train - Loss: 0.0247, MAE: 0.175mm, RMSE: 0.222mm, RÂ²: -0.464\n",
            "  Val   - Loss: 0.0252, MAE: 0.181mm, RMSE: 0.218mm, RÂ²: -0.045\n",
            "  Val Threshold Acc (@0.9mm): 0.570\n",
            "  LR: 0.001000\n",
            "  Patience: 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:43<00:00,  1.04it/s, loss=0.0259]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 15/30:\n",
            "  Train - Loss: 0.0259, MAE: 0.181mm, RMSE: 0.228mm, RÂ²: -0.538\n",
            "  Val   - Loss: 0.0148, MAE: 0.143mm, RMSE: 0.174mm, RÂ²: 0.334\n",
            "  Val Threshold Acc (@0.9mm): 0.800\n",
            "  LR: 0.001000\n",
            "  Patience: 2/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:43<00:00,  1.04it/s, loss=0.0226]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 16/30:\n",
            "  Train - Loss: 0.0226, MAE: 0.168mm, RMSE: 0.213mm, RÂ²: -0.343\n",
            "  Val   - Loss: 0.0156, MAE: 0.143mm, RMSE: 0.175mm, RÂ²: 0.324\n",
            "  Val Threshold Acc (@0.9mm): 0.700\n",
            "  LR: 0.000100\n",
            "  Patience: 3/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:44<00:00,  1.04it/s, loss=0.0212]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 17/30:\n",
            "  Train - Loss: 0.0212, MAE: 0.162mm, RMSE: 0.206mm, RÂ²: -0.258\n",
            "  Val   - Loss: 0.0138, MAE: 0.137mm, RMSE: 0.167mm, RÂ²: 0.389\n",
            "  Val Threshold Acc (@0.9mm): 0.755\n",
            "  LR: 0.000100\n",
            "  âœ… New best MAE: 0.1372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:44<00:00,  1.03it/s, loss=0.0211]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 18/30:\n",
            "  Train - Loss: 0.0211, MAE: 0.163mm, RMSE: 0.206mm, RÂ²: -0.257\n",
            "  Val   - Loss: 0.0146, MAE: 0.141mm, RMSE: 0.170mm, RÂ²: 0.365\n",
            "  Val Threshold Acc (@0.9mm): 0.715\n",
            "  LR: 0.000100\n",
            "  Patience: 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:47<00:00,  1.01it/s, loss=0.0228]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 19/30:\n",
            "  Train - Loss: 0.0228, MAE: 0.169mm, RMSE: 0.214mm, RÂ²: -0.356\n",
            "  Val   - Loss: 0.0138, MAE: 0.136mm, RMSE: 0.167mm, RÂ²: 0.391\n",
            "  Val Threshold Acc (@0.9mm): 0.745\n",
            "  LR: 0.000100\n",
            "  âœ… New best MAE: 0.1365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:45<00:00,  1.03it/s, loss=0.0214]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 20/30:\n",
            "  Train - Loss: 0.0214, MAE: 0.164mm, RMSE: 0.207mm, RÂ²: -0.271\n",
            "  Val   - Loss: 0.0139, MAE: 0.137mm, RMSE: 0.167mm, RÂ²: 0.388\n",
            "  Val Threshold Acc (@0.9mm): 0.735\n",
            "  LR: 0.000100\n",
            "  Patience: 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:42<00:00,  1.05it/s, loss=0.0221]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 21/30:\n",
            "  Train - Loss: 0.0221, MAE: 0.166mm, RMSE: 0.210mm, RÂ²: -0.314\n",
            "  Val   - Loss: 0.0139, MAE: 0.137mm, RMSE: 0.167mm, RÂ²: 0.389\n",
            "  Val Threshold Acc (@0.9mm): 0.720\n",
            "  LR: 0.000100\n",
            "  Patience: 2/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:45<00:00,  1.03it/s, loss=0.0212]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 22/30:\n",
            "  Train - Loss: 0.0212, MAE: 0.164mm, RMSE: 0.206mm, RÂ²: -0.259\n",
            "  Val   - Loss: 0.0132, MAE: 0.134mm, RMSE: 0.164mm, RÂ²: 0.412\n",
            "  Val Threshold Acc (@0.9mm): 0.750\n",
            "  LR: 0.000100\n",
            "  âœ… New best MAE: 0.1342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:47<00:00,  1.01it/s, loss=0.0217]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 23/30:\n",
            "  Train - Loss: 0.0217, MAE: 0.166mm, RMSE: 0.208mm, RÂ²: -0.284\n",
            "  Val   - Loss: 0.0130, MAE: 0.133mm, RMSE: 0.164mm, RÂ²: 0.412\n",
            "  Val Threshold Acc (@0.9mm): 0.770\n",
            "  LR: 0.000100\n",
            "  âœ… New best MAE: 0.1328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:43<00:00,  1.04it/s, loss=0.0206]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 24/30:\n",
            "  Train - Loss: 0.0206, MAE: 0.161mm, RMSE: 0.203mm, RÂ²: -0.222\n",
            "  Val   - Loss: 0.0133, MAE: 0.135mm, RMSE: 0.165mm, RÂ²: 0.403\n",
            "  Val Threshold Acc (@0.9mm): 0.775\n",
            "  LR: 0.000100\n",
            "  Patience: 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:45<00:00,  1.02it/s, loss=0.0212]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 25/30:\n",
            "  Train - Loss: 0.0212, MAE: 0.164mm, RMSE: 0.206mm, RÂ²: -0.253\n",
            "  Val   - Loss: 0.0142, MAE: 0.139mm, RMSE: 0.168mm, RÂ²: 0.380\n",
            "  Val Threshold Acc (@0.9mm): 0.705\n",
            "  LR: 0.000100\n",
            "  Patience: 2/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:45<00:00,  1.02it/s, loss=0.02]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 26/30:\n",
            "  Train - Loss: 0.0200, MAE: 0.159mm, RMSE: 0.200mm, RÂ²: -0.192\n",
            "  Val   - Loss: 0.0141, MAE: 0.138mm, RMSE: 0.168mm, RÂ²: 0.382\n",
            "  Val Threshold Acc (@0.9mm): 0.725\n",
            "  LR: 0.000100\n",
            "  Patience: 3/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:42<00:00,  1.05it/s, loss=0.0218]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 27/30:\n",
            "  Train - Loss: 0.0218, MAE: 0.164mm, RMSE: 0.209mm, RÂ²: -0.290\n",
            "  Val   - Loss: 0.0135, MAE: 0.135mm, RMSE: 0.165mm, RÂ²: 0.401\n",
            "  Val Threshold Acc (@0.9mm): 0.760\n",
            "  LR: 0.000100\n",
            "  Patience: 4/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:44<00:00,  1.03it/s, loss=0.02]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 28/30:\n",
            "  Train - Loss: 0.0200, MAE: 0.158mm, RMSE: 0.200mm, RÂ²: -0.188\n",
            "  Val   - Loss: 0.0134, MAE: 0.133mm, RMSE: 0.166mm, RÂ²: 0.398\n",
            "  Val Threshold Acc (@0.9mm): 0.770\n",
            "  LR: 0.000100\n",
            "  Patience: 5/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:44<00:00,  1.04it/s, loss=0.0208]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 29/30:\n",
            "  Train - Loss: 0.0208, MAE: 0.162mm, RMSE: 0.204mm, RÂ²: -0.235\n",
            "  Val   - Loss: 0.0139, MAE: 0.133mm, RMSE: 0.168mm, RÂ²: 0.379\n",
            "  Val Threshold Acc (@0.9mm): 0.775\n",
            "  LR: 0.000100\n",
            "  Patience: 6/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:45<00:00,  1.02it/s, loss=0.0208]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 30/30:\n",
            "  Train - Loss: 0.0208, MAE: 0.161mm, RMSE: 0.204mm, RÂ²: -0.232\n",
            "  Val   - Loss: 0.0152, MAE: 0.141mm, RMSE: 0.173mm, RÂ²: 0.341\n",
            "  Val Threshold Acc (@0.9mm): 0.715\n",
            "  LR: 0.000100\n",
            "  Patience: 7/15\n",
            "\n",
            "Loading best model from Stage 1...\n",
            "âœ… Loaded best model with MAE: 0.1328\n"
          ]
        }
      ],
      "source": [
        "# Cell 12: Training Stage 1\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STAGE 1: Training with higher LR\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "best_metric = float('inf')  # Changed: lower is better for MAE\n",
        "patience_counter = 0\n",
        "training_history = []\n",
        "\n",
        "for epoch in range(1, STAGE1_EPOCHS + 1):\n",
        "    # Learning rate decay\n",
        "    if epoch > 1 and (epoch - 1) % STAGE1_LR_DECAY_EVERY == 0:\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] *= STAGE1_LR_DECAY_FACTOR\n",
        "\n",
        "    # Train\n",
        "    train_metrics = train_epoch(model, train_loader, criterion, optimizer, epoch)\n",
        "\n",
        "    # Validate\n",
        "    val_metrics = validate(model, val_loader, criterion)\n",
        "\n",
        "    # Log\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    print(f\"\\nEpoch {epoch}/{STAGE1_EPOCHS}:\")\n",
        "    print(f\"  Train - Loss: {train_metrics['loss']:.4f}, \"\n",
        "          f\"MAE: {train_metrics['mae']:.3f}mm, RMSE: {train_metrics['rmse']:.3f}mm, \"\n",
        "          f\"RÂ²: {train_metrics['r2']:.3f}\")\n",
        "    print(f\"  Val   - Loss: {val_metrics['loss']:.4f}, \"\n",
        "          f\"MAE: {val_metrics['mae']:.3f}mm, RMSE: {val_metrics['rmse']:.3f}mm, \"\n",
        "          f\"RÂ²: {val_metrics['r2']:.3f}\")\n",
        "    print(f\"  Val Threshold Acc (@{CIMT_THRESHOLD}mm): {val_metrics['threshold_accuracy']:.3f}\")\n",
        "    print(f\"  LR: {current_lr:.6f}\")\n",
        "\n",
        "    # Save best model (lower MAE is better)\n",
        "    current_metric = val_metrics[METRIC_FOR_BEST]\n",
        "    if current_metric < best_metric:\n",
        "        best_metric = current_metric\n",
        "        patience_counter = 0\n",
        "        print(f\"  âœ… New best {METRIC_FOR_BEST.upper()}: {best_metric:.4f}\")\n",
        "        if SAVE_BEST_MODEL:\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'best_metric': best_metric,\n",
        "                'val_metrics': val_metrics\n",
        "            }, CHECKPOINT_DIR / \"best_model_stage1.pth\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"  Patience: {patience_counter}/{EARLY_STOPPING_PATIENCE}\")\n",
        "\n",
        "    # Early stopping\n",
        "    if patience_counter >= EARLY_STOPPING_PATIENCE:\n",
        "        print(f\"\\nâš ï¸ Early stopping triggered at epoch {epoch}\")\n",
        "        break\n",
        "\n",
        "    # Save checkpoint\n",
        "    if epoch % SAVE_INTERVAL == 0:\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "        }, CHECKPOINT_DIR / f\"checkpoint_stage1_epoch{epoch}.pth\")\n",
        "\n",
        "    training_history.append({\n",
        "        'epoch': epoch,\n",
        "        'stage': 1,\n",
        "        'train_loss': train_metrics['loss'],\n",
        "        'train_mae': train_metrics['mae'],\n",
        "        'train_rmse': train_metrics['rmse'],\n",
        "        'train_r2': train_metrics['r2'],\n",
        "        'val_loss': val_metrics['loss'],\n",
        "        'val_mae': val_metrics['mae'],\n",
        "        'val_rmse': val_metrics['rmse'],\n",
        "        'val_r2': val_metrics['r2'],\n",
        "        'val_threshold_acc': val_metrics['threshold_accuracy'],\n",
        "        'lr': current_lr\n",
        "    })\n",
        "\n",
        "# Load best model from stage 1\n",
        "if SAVE_BEST_MODEL and (CHECKPOINT_DIR / \"best_model_stage1.pth\").exists():\n",
        "    print(\"\\nLoading best model from Stage 1...\")\n",
        "    checkpoint = torch.load(CHECKPOINT_DIR / \"best_model_stage1.pth\", weights_only=False)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"âœ… Loaded best model with {METRIC_FOR_BEST.upper()}: {checkpoint['best_metric']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "training_stage2",
        "outputId": "d4db979e-1bc1-43f7-8439-a65ee0c53dd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STAGE 2: Fine-tuning with lower LR\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:46<00:00,  1.02it/s, loss=0.0215]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/20:\n",
            "  Train - Loss: 0.0215, MAE: 0.162mm, RMSE: 0.208mm, RÂ²: -0.280\n",
            "  Val   - Loss: 0.0132, MAE: 0.135mm, RMSE: 0.164mm, RÂ²: 0.408\n",
            "  Val Threshold Acc (@0.9mm): 0.760\n",
            "  LR: 0.000010\n",
            "  âœ… New best MAE: 0.1345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:46<00:00,  1.01it/s, loss=0.0208]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2/20:\n",
            "  Train - Loss: 0.0208, MAE: 0.161mm, RMSE: 0.204mm, RÂ²: -0.237\n",
            "  Val   - Loss: 0.0132, MAE: 0.134mm, RMSE: 0.164mm, RÂ²: 0.411\n",
            "  Val Threshold Acc (@0.9mm): 0.760\n",
            "  LR: 0.000010\n",
            "  âœ… New best MAE: 0.1338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:45<00:00,  1.02it/s, loss=0.0213]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3/20:\n",
            "  Train - Loss: 0.0213, MAE: 0.163mm, RMSE: 0.207mm, RÂ²: -0.267\n",
            "  Val   - Loss: 0.0131, MAE: 0.134mm, RMSE: 0.164mm, RÂ²: 0.412\n",
            "  Val Threshold Acc (@0.9mm): 0.760\n",
            "  LR: 0.000010\n",
            "  âœ… New best MAE: 0.1336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:45<00:00,  1.02it/s, loss=0.0208]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4/20:\n",
            "  Train - Loss: 0.0208, MAE: 0.161mm, RMSE: 0.204mm, RÂ²: -0.237\n",
            "  Val   - Loss: 0.0133, MAE: 0.134mm, RMSE: 0.164mm, RÂ²: 0.408\n",
            "  Val Threshold Acc (@0.9mm): 0.760\n",
            "  LR: 0.000010\n",
            "  Patience: 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:45<00:00,  1.02it/s, loss=0.021]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5/20:\n",
            "  Train - Loss: 0.0210, MAE: 0.163mm, RMSE: 0.205mm, RÂ²: -0.249\n",
            "  Val   - Loss: 0.0133, MAE: 0.135mm, RMSE: 0.164mm, RÂ²: 0.408\n",
            "  Val Threshold Acc (@0.9mm): 0.755\n",
            "  LR: 0.000010\n",
            "  Patience: 2/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:45<00:00,  1.03it/s, loss=0.0213]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6/20:\n",
            "  Train - Loss: 0.0213, MAE: 0.164mm, RMSE: 0.206mm, RÂ²: -0.264\n",
            "  Val   - Loss: 0.0131, MAE: 0.133mm, RMSE: 0.164mm, RÂ²: 0.412\n",
            "  Val Threshold Acc (@0.9mm): 0.765\n",
            "  LR: 0.000010\n",
            "  âœ… New best MAE: 0.1330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:46<00:00,  1.01it/s, loss=0.0215]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7/20:\n",
            "  Train - Loss: 0.0215, MAE: 0.164mm, RMSE: 0.207mm, RÂ²: -0.271\n",
            "  Val   - Loss: 0.0132, MAE: 0.134mm, RMSE: 0.164mm, RÂ²: 0.411\n",
            "  Val Threshold Acc (@0.9mm): 0.760\n",
            "  LR: 0.000010\n",
            "  Patience: 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:45<00:00,  1.02it/s, loss=0.021]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8/20:\n",
            "  Train - Loss: 0.0210, MAE: 0.163mm, RMSE: 0.205mm, RÂ²: -0.246\n",
            "  Val   - Loss: 0.0130, MAE: 0.133mm, RMSE: 0.163mm, RÂ²: 0.415\n",
            "  Val Threshold Acc (@0.9mm): 0.760\n",
            "  LR: 0.000010\n",
            "  âœ… New best MAE: 0.1328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:45<00:00,  1.02it/s, loss=0.0209]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9/20:\n",
            "  Train - Loss: 0.0209, MAE: 0.163mm, RMSE: 0.205mm, RÂ²: -0.240\n",
            "  Val   - Loss: 0.0131, MAE: 0.133mm, RMSE: 0.163mm, RÂ²: 0.413\n",
            "  Val Threshold Acc (@0.9mm): 0.760\n",
            "  LR: 0.000010\n",
            "  Patience: 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:47<00:00,  1.01it/s, loss=0.0215]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10/20:\n",
            "  Train - Loss: 0.0215, MAE: 0.162mm, RMSE: 0.207mm, RÂ²: -0.275\n",
            "  Val   - Loss: 0.0131, MAE: 0.134mm, RMSE: 0.163mm, RÂ²: 0.414\n",
            "  Val Threshold Acc (@0.9mm): 0.755\n",
            "  LR: 0.000010\n",
            "  Patience: 2/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:45<00:00,  1.02it/s, loss=0.0206]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 11/20:\n",
            "  Train - Loss: 0.0206, MAE: 0.160mm, RMSE: 0.203mm, RÂ²: -0.224\n",
            "  Val   - Loss: 0.0132, MAE: 0.134mm, RMSE: 0.164mm, RÂ²: 0.413\n",
            "  Val Threshold Acc (@0.9mm): 0.755\n",
            "  LR: 0.000001\n",
            "  Patience: 3/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:47<00:00,  1.01it/s, loss=0.0193]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 12/20:\n",
            "  Train - Loss: 0.0193, MAE: 0.156mm, RMSE: 0.196mm, RÂ²: -0.146\n",
            "  Val   - Loss: 0.0133, MAE: 0.135mm, RMSE: 0.164mm, RÂ²: 0.408\n",
            "  Val Threshold Acc (@0.9mm): 0.750\n",
            "  LR: 0.000001\n",
            "  Patience: 4/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:45<00:00,  1.02it/s, loss=0.0202]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 13/20:\n",
            "  Train - Loss: 0.0202, MAE: 0.161mm, RMSE: 0.201mm, RÂ²: -0.204\n",
            "  Val   - Loss: 0.0130, MAE: 0.133mm, RMSE: 0.163mm, RÂ²: 0.415\n",
            "  Val Threshold Acc (@0.9mm): 0.745\n",
            "  LR: 0.000001\n",
            "  Patience: 5/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:47<00:00,  1.01it/s, loss=0.0213]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 14/20:\n",
            "  Train - Loss: 0.0213, MAE: 0.164mm, RMSE: 0.206mm, RÂ²: -0.265\n",
            "  Val   - Loss: 0.0130, MAE: 0.133mm, RMSE: 0.163mm, RÂ²: 0.416\n",
            "  Val Threshold Acc (@0.9mm): 0.760\n",
            "  LR: 0.000001\n",
            "  Patience: 6/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:47<00:00,  1.01it/s, loss=0.021]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 15/20:\n",
            "  Train - Loss: 0.0210, MAE: 0.163mm, RMSE: 0.205mm, RÂ²: -0.248\n",
            "  Val   - Loss: 0.0131, MAE: 0.134mm, RMSE: 0.163mm, RÂ²: 0.413\n",
            "  Val Threshold Acc (@0.9mm): 0.750\n",
            "  LR: 0.000001\n",
            "  Patience: 7/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:46<00:00,  1.02it/s, loss=0.0204]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 16/20:\n",
            "  Train - Loss: 0.0204, MAE: 0.159mm, RMSE: 0.202mm, RÂ²: -0.214\n",
            "  Val   - Loss: 0.0130, MAE: 0.133mm, RMSE: 0.163mm, RÂ²: 0.416\n",
            "  Val Threshold Acc (@0.9mm): 0.750\n",
            "  LR: 0.000001\n",
            "  Patience: 8/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:43<00:00,  1.04it/s, loss=0.0202]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 17/20:\n",
            "  Train - Loss: 0.0202, MAE: 0.160mm, RMSE: 0.201mm, RÂ²: -0.199\n",
            "  Val   - Loss: 0.0131, MAE: 0.134mm, RMSE: 0.163mm, RÂ²: 0.414\n",
            "  Val Threshold Acc (@0.9mm): 0.755\n",
            "  LR: 0.000001\n",
            "  Patience: 9/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:45<00:00,  1.02it/s, loss=0.0216]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 18/20:\n",
            "  Train - Loss: 0.0216, MAE: 0.164mm, RMSE: 0.208mm, RÂ²: -0.284\n",
            "  Val   - Loss: 0.0132, MAE: 0.134mm, RMSE: 0.164mm, RÂ²: 0.412\n",
            "  Val Threshold Acc (@0.9mm): 0.750\n",
            "  LR: 0.000001\n",
            "  Patience: 10/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:46<00:00,  1.01it/s, loss=0.0204]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 19/20:\n",
            "  Train - Loss: 0.0204, MAE: 0.159mm, RMSE: 0.202mm, RÂ²: -0.211\n",
            "  Val   - Loss: 0.0131, MAE: 0.133mm, RMSE: 0.163mm, RÂ²: 0.416\n",
            "  Val Threshold Acc (@0.9mm): 0.750\n",
            "  LR: 0.000001\n",
            "  Patience: 11/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [01:46<00:00,  1.01it/s, loss=0.0197]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 20/20:\n",
            "  Train - Loss: 0.0197, MAE: 0.157mm, RMSE: 0.199mm, RÂ²: -0.170\n",
            "  Val   - Loss: 0.0133, MAE: 0.134mm, RMSE: 0.164mm, RÂ²: 0.409\n",
            "  Val Threshold Acc (@0.9mm): 0.755\n",
            "  LR: 0.000001\n",
            "  Patience: 12/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Cell 13: Training Stage 2 - Fine-tuning\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STAGE 2: Fine-tuning with lower LR\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=STAGE2_LR,\n",
        "                      weight_decay=WEIGHT_DECAY, betas=BETAS)\n",
        "\n",
        "best_metric = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(1, STAGE2_EPOCHS + 1):\n",
        "    # Learning rate decay\n",
        "    if epoch > 1 and (epoch - 1) % STAGE2_LR_DECAY_EVERY == 0:\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] *= STAGE2_LR_DECAY_FACTOR\n",
        "\n",
        "    # Train\n",
        "    train_metrics = train_epoch(model, train_loader, criterion, optimizer, epoch)\n",
        "\n",
        "    # Validate\n",
        "    val_metrics = validate(model, val_loader, criterion)\n",
        "\n",
        "    # Log\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    print(f\"\\nEpoch {epoch}/{STAGE2_EPOCHS}:\")\n",
        "    print(f\"  Train - Loss: {train_metrics['loss']:.4f}, \"\n",
        "          f\"MAE: {train_metrics['mae']:.3f}mm, RMSE: {train_metrics['rmse']:.3f}mm, \"\n",
        "          f\"RÂ²: {train_metrics['r2']:.3f}\")\n",
        "    print(f\"  Val   - Loss: {val_metrics['loss']:.4f}, \"\n",
        "          f\"MAE: {val_metrics['mae']:.3f}mm, RMSE: {val_metrics['rmse']:.3f}mm, \"\n",
        "          f\"RÂ²: {val_metrics['r2']:.3f}\")\n",
        "    print(f\"  Val Threshold Acc (@{CIMT_THRESHOLD}mm): {val_metrics['threshold_accuracy']:.3f}\")\n",
        "    print(f\"  LR: {current_lr:.6f}\")\n",
        "\n",
        "    # Save best model\n",
        "    current_metric = val_metrics[METRIC_FOR_BEST]\n",
        "    if current_metric < best_metric:\n",
        "        best_metric = current_metric\n",
        "        patience_counter = 0\n",
        "        print(f\"  âœ… New best {METRIC_FOR_BEST.upper()}: {best_metric:.4f}\")\n",
        "        if SAVE_BEST_MODEL:\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'best_metric': best_metric,\n",
        "                'val_metrics': val_metrics\n",
        "            }, CHECKPOINT_DIR / \"best_model_final.pth\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"  Patience: {patience_counter}/{EARLY_STOPPING_PATIENCE}\")\n",
        "\n",
        "    if patience_counter >= EARLY_STOPPING_PATIENCE:\n",
        "        print(f\"\\nâš ï¸ Early stopping triggered at epoch {epoch}\")\n",
        "        break\n",
        "\n",
        "    training_history.append({\n",
        "        'epoch': epoch,\n",
        "        'stage': 2,\n",
        "        'train_loss': train_metrics['loss'],\n",
        "        'train_mae': train_metrics['mae'],\n",
        "        'train_rmse': train_metrics['rmse'],\n",
        "        'train_r2': train_metrics['r2'],\n",
        "        'val_loss': val_metrics['loss'],\n",
        "        'val_mae': val_metrics['mae'],\n",
        "        'val_rmse': val_metrics['rmse'],\n",
        "        'val_r2': val_metrics['r2'],\n",
        "        'val_threshold_acc': val_metrics['threshold_accuracy'],\n",
        "        'lr': current_lr\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "final_evaluation",
        "outputId": "b24f3bd2-3523-4041-b25a-272efe5fd853"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "FINAL EVALUATION ON TEST SET\n",
            "============================================================\n",
            "Loading best model...\n",
            "âœ… Loaded best model with MAE: 0.1328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Set Results:\n",
            "  Loss: 0.0077\n",
            "  MAE: 0.105 mm\n",
            "  RMSE: 0.133 mm\n",
            "  RÂ²: 0.519\n",
            "  Threshold Accuracy (@0.9mm): 0.860\n",
            "\n",
            "âœ… Training history saved to /content/outputs/cimt_regression/results/training_history.csv\n",
            "âœ… Test results saved to /content/outputs/cimt_regression/results/test_results.json\n",
            "\n",
            "============================================================\n",
            "TRAINING COMPLETE!\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Cell 14: Final evaluation on test set\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL EVALUATION ON TEST SET\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if SAVE_BEST_MODEL and (CHECKPOINT_DIR / \"best_model_final.pth\").exists():\n",
        "    print(\"Loading best model...\")\n",
        "    checkpoint = torch.load(CHECKPOINT_DIR / \"best_model_final.pth\", weights_only=False)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"âœ… Loaded best model with {METRIC_FOR_BEST.upper()}: {checkpoint['best_metric']:.4f}\")\n",
        "\n",
        "test_metrics = validate(model, test_loader, criterion)\n",
        "\n",
        "print(\"\\nTest Set Results:\")\n",
        "print(f\"  Loss: {test_metrics['loss']:.4f}\")\n",
        "print(f\"  MAE: {test_metrics['mae']:.3f} mm\")\n",
        "print(f\"  RMSE: {test_metrics['rmse']:.3f} mm\")\n",
        "print(f\"  RÂ²: {test_metrics['r2']:.3f}\")\n",
        "print(f\"  Threshold Accuracy (@{CIMT_THRESHOLD}mm): {test_metrics['threshold_accuracy']:.3f}\")\n",
        "\n",
        "# Save training history\n",
        "history_df = pd.DataFrame(training_history)\n",
        "history_df.to_csv(RESULTS_DIR / \"training_history.csv\", index=False)\n",
        "print(f\"\\nâœ… Training history saved to {RESULTS_DIR / 'training_history.csv'}\")\n",
        "\n",
        "# Save test results\n",
        "test_results = {\n",
        "    'test_loss': test_metrics['loss'],\n",
        "    'test_mae': test_metrics['mae'],\n",
        "    'test_rmse': test_metrics['rmse'],\n",
        "    'test_r2': test_metrics['r2'],\n",
        "    'test_threshold_acc': test_metrics['threshold_accuracy']\n",
        "}\n",
        "\n",
        "import json\n",
        "with open(RESULTS_DIR / \"test_results.json\", 'w') as f:\n",
        "    json.dump(test_results, f, indent=2)\n",
        "print(f\"âœ… Test results saved to {RESULTS_DIR / 'test_results.json'}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING COMPLETE!\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inference_example",
        "outputId": "62b1e30a-3b2b-4ae3-cd80-e809bbf1025f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Making predictions on test samples...\n",
            "\n",
            "       patient_id  predicted_cimt  true_cimt    error predicted_class true_class\n",
            "tensor(151594008)        1.018096        1.1 0.081904       Thickened  Thickened\n",
            "tensor(151932002)        1.014267        0.9 0.114267       Thickened  Thickened\n",
            "tensor(152071010)        1.071923        1.1 0.028077       Thickened  Thickened\n",
            "tensor(152073003)        1.040416        1.1 0.059584       Thickened  Thickened\n",
            "tensor(152584002)        0.992586        0.9 0.092586       Thickened  Thickened\n",
            "tensor(153884002)        1.018700        1.0 0.018700       Thickened  Thickened\n",
            "tensor(155500003)        1.032282        1.1 0.067718       Thickened  Thickened\n",
            "tensor(155500005)        1.029913        1.4 0.370087       Thickened  Thickened\n",
            "tensor(157612002)        0.928235        1.0 0.071765       Thickened  Thickened\n",
            "tensor(157742003)        1.032693        1.2 0.167307       Thickened  Thickened\n",
            "\n",
            "Average prediction error: 0.107 mm\n"
          ]
        }
      ],
      "source": [
        "# Cell 15: Inference example (optional)\n",
        "# Example: Make predictions on a few samples\n",
        "\n",
        "def predict_cimt(model, dataloader, num_samples=5):\n",
        "    \"\"\"\n",
        "    Make predictions on a few samples and compare with ground truth.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    results = []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            left_img = batch['left_image'].to(DEVICE)\n",
        "            right_img = batch['right_image'].to(DEVICE)\n",
        "            clinical = batch['clinical'].to(DEVICE)\n",
        "            targets = batch['cimt'].cpu().numpy()\n",
        "            patient_ids = batch['patient_id']\n",
        "\n",
        "            predictions = model(left_img, right_img, clinical)\n",
        "            predictions = predictions.cpu().numpy()\n",
        "\n",
        "            for i in range(len(predictions)):\n",
        "                pred_val = predictions[i][0]\n",
        "                true_val = targets[i][0]\n",
        "                error = abs(pred_val - true_val)\n",
        "\n",
        "                results.append({\n",
        "                    'patient_id': patient_ids[i],\n",
        "                    'predicted_cimt': pred_val,\n",
        "                    'true_cimt': true_val,\n",
        "                    'error': error,\n",
        "                    'predicted_class': 'Thickened' if pred_val >= CIMT_THRESHOLD else 'Normal',\n",
        "                    'true_class': 'Thickened' if true_val >= CIMT_THRESHOLD else 'Normal'\n",
        "                })\n",
        "\n",
        "                if len(results) >= num_samples:\n",
        "                    break\n",
        "\n",
        "            if len(results) >= num_samples:\n",
        "                break\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Make predictions on test set\n",
        "print(\"Making predictions on test samples...\\n\")\n",
        "predictions_df = predict_cimt(model, test_loader, num_samples=10)\n",
        "print(predictions_df.to_string(index=False))\n",
        "\n",
        "print(f\"\\nAverage prediction error: {predictions_df['error'].mean():.3f} mm\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== SAVE THE CURRENT MODEL (ALREADY TRAINED) ====================\n",
        "\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"Saving the fully-trained model that's currently in memory...\")\n",
        "\n",
        "# Save the model that's already been trained\n",
        "final_checkpoint = {\n",
        "    'epoch': 50,  # Or STAGE1_EPOCHS + STAGE2_EPOCHS\n",
        "    'stage1_epochs': 30,\n",
        "    'stage2_epochs': 20,\n",
        "    'model_state_dict': model.state_dict(),  # Current model in memory\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'best_mae': best_metric if 'best_metric' in locals() else None,\n",
        "    'training_complete': True,\n",
        "    'metrics': {\n",
        "        'best_mae': float(best_metric) if 'best_metric' in locals() else None,\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save it\n",
        "save_path = Path('/content/cimt_fully_trained_epoch50.pth')\n",
        "torch.save(final_checkpoint, save_path)\n",
        "\n",
        "print(f\"\\nâœ… SAVED!\")\n",
        "print(f\"   Path: {save_path}\")\n",
        "print(f\"   Epoch: 50\")\n",
        "\n",
        "# Download it\n",
        "from google.colab import files\n",
        "files.download(str(save_path))\n",
        "\n",
        "print(\"\\nâœ… Downloaded! This is your fully-trained model.\")"
      ],
      "metadata": {
        "id": "TBxrcM_0CG5Z",
        "outputId": "c719d93e-3761-4492-c6d1-4323d69b6c3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving the fully-trained model that's currently in memory...\n",
            "\n",
            "âœ… SAVED!\n",
            "   Path: /content/cimt_fully_trained_epoch50.pth\n",
            "   Epoch: 50\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_182aac9a-6f1d-4a82-a210-dbaf0a83a0d9\", \"cimt_fully_trained_epoch50.pth\", 333515119)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Downloaded! This is your fully-trained model.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ec2036c7c6bf4296a1d53486fb53d7e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d44539a7d1f4bbf99c8180dcf89b27f",
              "IPY_MODEL_33b0432244b5448b80b9185df53fbe36",
              "IPY_MODEL_540051b772f54fcbb090fe43db119f29"
            ],
            "layout": "IPY_MODEL_4681fd8a45524777b2c0b8e7a0879dd4"
          }
        },
        "8d44539a7d1f4bbf99c8180dcf89b27f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac2fc7729021457aa9453ed093b43cd1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7a51a3efc0894cfebb1f91e7bc8baccb",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "33b0432244b5448b80b9185df53fbe36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a3b57d33e8044c28925e6d633f06058",
            "max": 110547680,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9ffb805a967463486f7159ca88bdd33",
            "value": 110547680
          }
        },
        "540051b772f54fcbb090fe43db119f29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bda35c0235cc48e28b39055a1e00d8d9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_639c138a1ecd4cdb8f2c1208b54dee91",
            "value": "â€‡111M/111Mâ€‡[00:02&lt;00:00,â€‡60.7MB/s]"
          }
        },
        "4681fd8a45524777b2c0b8e7a0879dd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac2fc7729021457aa9453ed093b43cd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a51a3efc0894cfebb1f91e7bc8baccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a3b57d33e8044c28925e6d633f06058": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9ffb805a967463486f7159ca88bdd33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bda35c0235cc48e28b39055a1e00d8d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "639c138a1ecd4cdb8f2c1208b54dee91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}